{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dee76a7-f08d-44a6-9fb9-7d6ff3fd1f54",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aae96ede-be95-4ad4-b155-d9f30c47a956",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make the plots bigger\n",
    "plt.rcParams[\"figure.figsize\"] = (10,10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69991b89-f8fa-495a-94ef-db00067ceedd",
   "metadata": {},
   "source": [
    "# Image segmentation \n",
    "\n",
    "Segmentation is the process of separating pieces out of the whole. In computer vision this tends to refer to separating groups of pixels and grouping them together.       \n",
    "Segmentation is useful because it allows us to say \"this is a ball\" and \"this is a square\". There are many things that fall under segmentation in general, but here we will cover the one provided by OpenCV `findContours` function. \n",
    "\n",
    "Contours can be a bit difficult to explain because on face-value they look kind of like what edge detection algorithms do. However, they are indeed more powerful, because instead of an bitmap image, denoting a kind of a map of pixels that belong to an edge, contours provide us with the edge boundaries and their relationship to other boundaries.        \n",
    "This makes a big difference because it allows us to test the properties of these objects. \n",
    "\n",
    "For now, let's quickly whip up an example of edges:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87b1cc15-a8d7-42ac-a43b-6522cc284f9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import ndimage\n",
    "\n",
    "img = np.zeros((256, 256), dtype=np.uint8)\n",
    "img[64:-64, 64:-64] += 3\n",
    "img[32:-32, 32:-32] += 2\n",
    "img[16:-16, 16:-16] += 1\n",
    "plt.imshow(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fd61443-f415-46d6-adce-1e4905de07cc",
   "metadata": {},
   "source": [
    "Let's repeat what we did in the previous excercise and detect edges:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ce2a625-e1ea-462b-800e-9e7dee870306",
   "metadata": {},
   "outputs": [],
   "source": [
    "edges = cv2.Canny(img, 0, 1)\n",
    "plt.imshow(edges)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f78ee209-4f13-42da-af60-ecebe5fa5726",
   "metadata": {},
   "source": [
    "# Contours\n",
    "\n",
    "Everything you could possibly want to learn about contours can be found in the [OpenCV Contours Tutorials](https://docs.opencv.org/3.4/d3/d05/tutorial_py_table_of_contents_contours.html). At this point I would most heartily recommend that you at least cover the [Getting Started](https://docs.opencv.org/3.4/d4/d73/tutorial_py_contours_begin.html) portion of OpenCV tutorials because they will demistify what the function arguments are and what contours are.\n",
    "\n",
    "After that feel free to jump back to this notebook where I will attempt to demistify what the function returns back. Unfortunately, due to the historical ties of OpenCV to C++ the returned values are somewhat confusing. More than some deep knowledge about contours, I aimed to impart in this notebook a sort-of how-to on code sleuthing on a set of practical examples. I think it's important because more than once you'll find yourself trying to wrap your head around a piece of OpenCV nonsense. We will eventually and periodically return to the topic at hand throughout the text, so there is a chance there is worthy information there, however, if this is not something you feel like you struggle with - jump straight to the second OpenCV tutorial on [Contour Features](https://docs.opencv.org/3.4/dd/d49/tutorial_py_contour_features.html), [Contour Properties](https://docs.opencv.org/3.4/d1/d32/tutorial_py_contour_properties.html) and then jump to the bottom of the notebook titled \"Fitting Minimal Area Rectangles\". \n",
    "\n",
    "So, having either read the tutorial, or having pressed the \"I believe\" button and skipped it, let's move on:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "514b4ec3-f89b-4982-8c35-6fd44707d197",
   "metadata": {},
   "outputs": [],
   "source": [
    "contours, hierarchy = cv2.findContours(edges, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7fa51eb-32f0-4e4a-8f25-c45baed9e8a8",
   "metadata": {},
   "source": [
    "Let's visualize this in the same way the [Getting Started](https://docs.opencv.org/3.4/d4/d73/tutorial_py_contours_begin.html) tutorial showed us:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "631c88a4-6301-484c-9951-7094e21ddcb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "cimg = np.zeros((256, 256), dtype=np.uint8)\n",
    "cv2.drawContours(cimg, contours, -1, (255,255,255), 1)\n",
    "plt.imshow(cimg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3fe38eb-fcf5-4011-8c01-41ea22f07a59",
   "metadata": {},
   "source": [
    "Hmm, but that looks exactly the same as does the output of Canny edge detector?!             \n",
    "So what even is the point of contours?\n",
    "\n",
    "Let's look at what it actually returned to us:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1987cc27-fd70-49bd-801c-dedaf65c1935",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"First Returned Value: contours\")\n",
    "print(\"    type: \", type(contours))\n",
    "print(\"    len: \", len(contours))\n",
    "print(\"    len(contours[0]): \", len(contours[0]))\n",
    "print(\"First element of contours: \")\n",
    "print(contours[0])\n",
    "\n",
    "print()\n",
    "print()\n",
    "print()\n",
    "\n",
    "print(\"Second Returned Value: hierarchy\")\n",
    "print(\"    type: \", type(hierarchy))\n",
    "print(\"    len: \", len(hierarchy))\n",
    "print(\"    len(hierarchy[0]): \", len(hierarchy[0]))\n",
    "print(\"First element of hierarchy: \")\n",
    "print(hierarchy[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a88035df-b663-4c98-be73-62b712ac1065",
   "metadata": {},
   "source": [
    "So how do we make sense of this? Drawing them just makes an image of edges so that's a bust. How many contours did we even found? What are these points even? And how do we interpret the hierarchy matrix?\n",
    "\n",
    "Here's what the documentation has to say about it:\n",
    "\n",
    "```\n",
    "    contours \t Detected contours. Each contour is stored as a vector of points (e.g. std::vector<std::vector<cv::Point> >).\n",
    "    hierarchy \t Optional output vector (e.g. std::vector<cv::Vec4i>), containing information about the image topology. It has as many elements as the number of contours. For each i-th contour contours[i], the elements hierarchy[i][0] , hierarchy[i][1] , hierarchy[i][2] , and hierarchy[i][3] are set to 0-based indices in contours of the next and previous contours at the same hierarchical level, the first child contour and the parent contour, respectively. If for the contour i there are no next, previous, parent, or nested contours, the corresponding elements of hierarchy[i] will be negative.\n",
    "\n",
    "Note\n",
    "    In Python, hierarchy is nested inside a top level array. Use hierarchy[0][i] to access hierarchical elements of i-th contour. \n",
    "```\n",
    "\n",
    "That doesn't really make sense to me to be honest, except that apparently the length of hierarchy is the number of detected contours. So let's try to manually plot some points:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4adbd2bf-a209-4f41-9eb0-300bd3755335",
   "metadata": {},
   "outputs": [],
   "source": [
    "for point in contours[0]:\n",
    "    plt.scatter(*point)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0b9cc2d-8396-42b2-9a3d-9cbf25e391b4",
   "metadata": {},
   "source": [
    "Let's decompose the above for loop. First let's make it clear what we want.                 \n",
    "\n",
    "We want to plot all the point of a single contour.           \n",
    "We want to use [matplotlib scatter](https://matplotlib.org/stable/api/_as_gen/matplotlib.pyplot.scatter.html) function to do that.       \n",
    "The `scatter` function expects the coordinates of a point in the plot, i.e. `plt.scatter(x, y)`, therefore we want to find a way to access the points of the first contour that give us the coordinates `(x, y)` of the edge of the contour. Seems reasonable enough. \n",
    "\n",
    "My personal natural instinct would be that `contours` is a list of detected contours. Each contour itself would be a list of points making up the edges of the contour. So accessing an elements of the list `contours` would given me n-th detected contour and accessing the elements of that would give me the `j-th` point of the `i-th` contour.  \n",
    "\n",
    "So, my personal natural instinct would be to expect contour to be a list of points such as `[(x1, y1), (x2, y2), ...]`. Once I iterate over that list, I would iterate over individual points`(x1, y1)` then `(x2, y2)` and so on. If this were the case I could use the special operator `*`, called the unpacking operator, to plot my points on the graph.\n",
    "\n",
    "The unpacking operator unpacks an array of values and passes them as individual positional arguments to a function. Effectively, when you want to call a function with multiple arguments, whose values you calculated and added to an array, can use the unpacking operator. Unpacking operator effectively performs the following: `*(x1, x2, x3...) --> x1, x2, x3...`, so when we plot `plt.scatter(*(x1, y1))` Python understands it as `plt.plot(x1, y1)`.                       \n",
    "The unpacking operator has a big brother `**` that also works on dictionaries, in which case they would be passed in as keyword arguments instead of positional arguments. So having a dictionary of values like `d = {\"arg1\": 1, \"arg2\": 2}` and doing `function(**d)` would be interpreted by Python as `func(arg1=1, arg2=2)`.\n",
    "\n",
    "So after that little detour back to the for-loop above. So far we expected that `contours` was a list of detected contours and that accessing an element of that list would give me the `i-th` detected contour and accessing an element of `i-th` contour gives me its `j-th` point as a tuple `(x_j, y_j)`.\n",
    "\n",
    " \n",
    "It looks like we can select the i-th contour by `contours[i]`, so in our for loop `contours[0`] selects the first contour.   \n",
    "\n",
    "However, if I try that then `plt.scatter` complains that it's missing a second coordinate.          \n",
    "Trye printing what `point` is. If I print it I see output like `[(x1, y1)]` instead of `(x1, y1)`.        \n",
    "It seems that, instead of what we expected to get, which is `(x1, y1)`, what we got is `[(x1, y1)]`.               \n",
    "\n",
    "Therefore `contours` is a list of arrays of points, like `[ [(x1, y1)], [(x2, y2)], [(x3, y3)] ... ]` instead of `[(x1, y1), (x2, y2)...]`. \n",
    "\n",
    "So when we try to call `plt.scatter(*point)` it is interpreted as `plt.scatter((x1, y1))` instead of `plt.scatter(x1, y1)`. \n",
    "\n",
    "So, how do we fix this?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62ecc413-ad30-404d-aa57-9097d68d58ca",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "63b9ea54-0c85-4e61-be0a-8635b35f2eca",
   "metadata": {},
   "source": [
    "Why do we get a list of arrays of point-tuples and does that mean something? \n",
    "\n",
    "In short, no. The reason is that OpenCV is written `C++` and there is a little bit of conversion that occurs when transiting from `C++` types to `Python` types. Someone, long ago wrote something that made sense in C++ but didn't in Python. This is a famous OpenCV \"feature\".         \n",
    "I guess nobody's perfect.\n",
    "\n",
    "In any case, let's move on and inspect more contours. Let's plot all of the contours in separate plots with different titles and colors. After all there's only 6 of them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c8f1e5c-30d9-4323-8889-fa0d089a150e",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(2, 3, figsize=(15, 10), sharex=True, sharey=True)\n",
    "i = 0\n",
    "for ax, cnt, color in zip(axes.ravel(), contours, (\"red\", \"blue\", \"green\", \"orange\",\"black\", \"gray\")):\n",
    "    for point in cnt:\n",
    "        ax.scatter(*point[0], color=color)\n",
    "        ax.set_title(f\"Contour {i}\")\n",
    "    i+=1\n",
    "    ax.set_xlim(0, 256)\n",
    "    ax.set_ylim(0, 256)\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "897e5136-630f-4914-82c2-71cea056eb1d",
   "metadata": {},
   "source": [
    "Hmm, interesting! \n",
    "\n",
    "So it found the \"same\" contours as different contours, with the difference being only a couple of pixels. \n",
    "\n",
    "The contours are lines that track pixels of the same intensity - there is no requirement for this to be a closed curve whatsoever. It could be that the algorithm noticed the edges of the squares. where even we can see the pixel intensity is not as large, failed to close the contour and then double-backed on it. It could be that the fuzzy corners also made the contours detect the same one multiple times, just offset by a pixel or two. \n",
    "\n",
    "Whatever it is, we definitely need to be careful to properly filter our retrieved contours. So let's. \n",
    "\n",
    "Here, it would be of great benefit to check out all the kinds of properties and features contours have in the OpenCV  [Contour Features](https://docs.opencv.org/3.4/dd/d49/tutorial_py_contour_features.html) and [Contour Properties](https://docs.opencv.org/3.4/d1/d32/tutorial_py_contour_properties.html) tutorials. They are really short and basically showcase why contours are so much more powerful than edge bitmaps - they are segmented!\n",
    "\n",
    "If it didn't occur to you, we just plotted each individual contour - individually! This is a huge step forward compared to outputs of Canny edge detector. In combination with their properties we suddenly have significantly more information on the shapes, sizes, orientations and positions of the individual clumps of pixels in our image compare to just knowing which pixels might belong to a clump but not even knowing which one they belong to! \n",
    "\n",
    "To filter duplicated contours I looked up what property I could best take advantage of, decided it was area, and then removed contours of similar areas. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f98bd9e8-4b64-4b13-8232-98a8d9ad2e8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this just makes life a bit easier\n",
    "# do note that not all contours have the same number of points \n",
    "# and numpy hates this so we need to specify dtype=object to appease it\n",
    "contours = np.array(contours, dtype=object)\n",
    "\n",
    "areas = []\n",
    "for cnt in contours:\n",
    "    areas.append(cv2.contourArea(cnt))\n",
    "print(\"All areas: \", areas)\n",
    "\n",
    "\n",
    "# if the contours area are different by more than 5% of\n",
    "# total image area we consider them different.\n",
    "dimx, dimy = img.shape\n",
    "total_image_area = dimx*dimy\n",
    "area_threshold = 0.1 * total_image_area\n",
    "\n",
    "# diff gives me the differences between neighbouring elements\n",
    "# so 1st minus 2nd, 2nd minus 3rd etc...\n",
    "# We can use this here because we know they are neatly ordered, \n",
    "# otherwise we might have to be a bit more clever.\n",
    "diff = np.abs(np.diff(areas))\n",
    "same_cnts = diff < area_threshold\n",
    "\n",
    "# note that our indices will be 1 off because how diff works\n",
    "# so we add the 1st element by hand and then add the rest after it\n",
    "duplicates = [False]\n",
    "duplicates.extend(same_cnts)\n",
    "print(\"Duplicate contour: \", duplicates)\n",
    "\n",
    "# so let's finally select the non-dupes\n",
    "contours = contours[np.logical_not(duplicates)]\n",
    "\n",
    "print(f\"Selected {len(contours)} contours, rejected {duplicates.count(True)} contours as duplicates.\")\n",
    "cimg = np.zeros((256, 256), dtype=np.uint8)\n",
    "cv2.drawContours(cimg, contours, -1, (255,255,255), 1)\n",
    "plt.imshow(cimg)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "196a78ac-7875-4942-b332-67e33dd960d5",
   "metadata": {},
   "source": [
    "So why have this section here and what have we learned?\n",
    "\n",
    "Image algorithms are not perfect. They stumble, probably, more so than other algorithms from the CS domain. This is to be expected because Computer Vision is hard. Especially for computers. This same situation will occur again, soonest probably already in the following exercise where we use Hough Transform to detect lines, except in that case I won't provide the detailed walkthrough on how to debug issues, filter results and wrap your head around the weird OpenCV output formats. Hopefully, there are lessons and tricks you can take away from this hands on example, that you can apply there as well.\n",
    "\n",
    "## Fitting minimal area rectangles\n",
    "\n",
    "Let's take a different example, where we can see how poweful knowing moments (f.e. circumference, area, etc..) of our contours can be. Here we will experiment a little with a particular function that fits minimal area rectangles to contours, found in the [Contour Features](https://docs.opencv.org/3.4/dd/d49/tutorial_py_contour_features.html) tutorial. \n",
    "\n",
    "To save us some time repeating the above, I've pre-made a bitmap, let's jump straight to detected edges."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "368e0454-270c-43d0-8004-d59153ab72fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread(\"images/bitmap.png\", cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "contours, hierarchy = cv2.findContours(img, cv2.RETR_TREE, cv2.CHAIN_APPROX_NONE)\n",
    "\n",
    "cimg = np.zeros(img.shape, dtype=np.uint8)\n",
    "cv2.drawContours(cimg, contours, -1, (255,255,255), 1)\n",
    "plt.imshow(cimg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b5c89ad-514b-4cee-9b84-5feeb8f8cb2f",
   "metadata": {},
   "source": [
    "The function of interest here, is `cv2.minAreaRect` function. Let's see what it's docstring can tell us"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30c42f7f-24ce-4561-9fe3-23bddbe50759",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.minAreaRect?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13500a4c-5a28-4ce0-b646-1a696c53d048",
   "metadata": {},
   "source": [
    "Let's just fit all min area rectangles we can."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b89a9cc-e93d-461a-89c2-2505068a5a09",
   "metadata": {},
   "outputs": [],
   "source": [
    "cimg = np.zeros(img.shape, dtype=np.uint8)\n",
    "treshold = 5\n",
    "\n",
    "rectangles = []\n",
    "for cnt in contours: \n",
    "    rect = cv2.minAreaRect(cnt) # [x, y, w, h, theta]\n",
    "    rectangles.append(rect)\n",
    "    \n",
    "    # let's draw them simultaneously so we save some space\n",
    "    box = cv2.boxPoints(rect)\n",
    "    box = np.asarray(box, dtype=np.int32)\n",
    "    cv2.fillPoly(cimg, [box], (255, 255, 255))\n",
    "\n",
    "plt.imshow(cimg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb506273-f5b5-4f82-85a5-7ea0e6c87bc0",
   "metadata": {},
   "source": [
    "Hmm, interesting that `minAreaRect` found 2 equivalent solutions to fitting squares to circles, reminds you of something we just saw above perhaps?\n",
    "\n",
    "If you feel like it, feel free to try to use some properties and features of contours to remove duplicate rectangles in the image, but as far as the main line of the notebook goes, we are interested only in the line features. How can we extract those?\n",
    "\n",
    "Naturally, lines on images are really loooong looooooooong rectangles. So let's check their sides maybe?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4f8fe3c-8d6d-4b97-aa88-501eddbfda44",
   "metadata": {},
   "outputs": [],
   "source": [
    "cimg = np.zeros(img.shape, dtype=np.uint8)\n",
    "\n",
    "treshold = 5\n",
    "lines = []\n",
    "for cnt in contours: \n",
    "    rect = cv2.minAreaRect(cnt) # [x, y, w, h, theta]\n",
    "    box = cv2.boxPoints(rect)\n",
    "    box = np.asarray(box, dtype=np.int32)\n",
    "    \n",
    "    # lines are really long - i.e. one of their sides\n",
    "    # is much larger than the other. Let's say if\n",
    "    # one of the sides is threshold times the other one\n",
    "    # we reject it!\n",
    "    (x,y), (w, h), theta = rect\n",
    "    if (w/h > treshold) or (h/w > treshold):\n",
    "        lines.append(rect)\n",
    "        cv2.fillPoly(cimg, [box], (255, 255, 255))\n",
    "        \n",
    "plt.imshow(cimg)    \n",
    "print(lines)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "960f71b1-c50f-4a56-ba8c-20df05ddcdff",
   "metadata": {},
   "source": [
    "So you see, contours do give us more information about our objects! What other properties or features of contours could be useful to us?\n",
    "\n",
    "# Summary\n",
    "\n",
    "* Image segmentation is the process of finding and grouping of pixels into objects and expressing their relations to one another. \n",
    "* Contour finding algorithms are a powerful tool for image segmentation\n",
    "  * This is because they provide shape descriptions and ordering of the detected objects in our image\n",
    "* Unfortunately they operate only on bitmaps (images with 1 or 0 only)\n",
    "  * This requires us to either treshold our image beforehand, in such a way we produce edges, or run an edge detection algorithm\n",
    "  * They can also be somewhat \"dirty\" - requiring us to filter out duplicates\n",
    "* All lines on images can be considered as \"rectangles\" with, at least a minimum, side length of 1 pixel\n",
    "  * Lines are long which means we can use the moments of our contours to find out whether or not the found contour looks like an \n",
    "    thin long object or if it's curcular or if etc.. \n",
    "  * We can also use these properties to figure out if they are duplicates or not."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
