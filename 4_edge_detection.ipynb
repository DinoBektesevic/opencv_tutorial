{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6f8daec-b23c-4e33-8aef-17c7c0ef69fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "149ec9de-02e1-4911-a09f-fa2ee8513a98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make the plots bigger\n",
    "plt.rcParams[\"figure.figsize\"] = (10,10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45a4c109-293a-4fba-a8b4-81ed259e5626",
   "metadata": {},
   "source": [
    "# Edges\n",
    "\n",
    "Let's take a step back from directly looking at images and think about one of the most useful mathematical operations that we had not yet considered - the derivative.\n",
    "\n",
    "Derivatives give us the rate of change of a function. So for example,  for the following function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9e8641d-3695-4ac5-b8ab-1d2b72954782",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_function_samples(width=20):\n",
    "    \"\"\"Generates samples of an ad-hoc smooth step-like function of a specified width.\"\"\"\n",
    "    a = np.zeros((100, ))\n",
    "    b = np.linspace(-7, 7, width)\n",
    "    b = 1/(1+np.exp(-b))\n",
    "    a[25:45] = b\n",
    "    a[45:55] = b[-1]\n",
    "    a[55:75] = b[::-1]\n",
    "    return a\n",
    "    \n",
    "f = generate_function_samples()\n",
    "plt.plot(f)\n",
    "plt.title(\"Plateau function\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "434a8fe8-f98f-40f8-bb7e-f803e0b9dd11",
   "metadata": {},
   "source": [
    "It seems reasonable to say the derivatives will peak when the function grows and falls, but that they would be near zero in the flat regions.\n",
    "\n",
    "We can verify this by:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae8bb14b-cced-46e3-ab2c-216bafe7e1ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = np.gradient(f)\n",
    "plt.plot(df)\n",
    "_ = plt.title(\"Derivative of the plateau function.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f4c4a42-b411-4f02-b778-0c70180db936",
   "metadata": {},
   "source": [
    "In mathematics you've (hopefully) seen plenty of times how to find extrema of a function, i.e. \"peaks\" of a function, by equating the derivative with a zero and then solving for the variable(s). This is because at the peak, the function transitions from a increasing to a decreasing one. To do that, the slope of that function must at some point pass through a line that is parallel to the x axis - meaning, that at some point the slope must be zero. \n",
    "\n",
    "However, what we will be interested more in today, are the maxima and minima of the derivatives. Let's find the index in which they occur.           \n",
    "Can you already guess why?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76328bf1-a6d4-4a01-9e8b-375a615d6777",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_val, min_val = df.max(), df.min()\n",
    "max_idx = np.where(df == max_val)[0][0]\n",
    "min_idx = np.where(df == min_val)[0][0]\n",
    "print(f\"Idx max: {max_idx}\")\n",
    "print(f\"Idx min: {min_idx}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2729a156-dbda-4d85-95c9-e701028adcc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(f)\n",
    "plt.axvline(max_idx, color=\"black\", label=\"max(gf)\")\n",
    "plt.axvline(min_idx, color=\"red\", label=\"min(gf)\")\n",
    "plt.legend()\n",
    "plt.title(\"Plateau function\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d21ce3fc-577d-46ec-b42b-bb8deb30b83d",
   "metadata": {},
   "source": [
    "Ok, cool. So in some ways the derivatives can find \"edges\" of functions, defined as the width between the maxima and minima of convex or concave functions.         \n",
    "It seems defining an \"edge\" of a function is more tricky than one would want. Namely, it is obvious that we have in general managed to locate where our function is, but we are missing some of the \"signal\" on the edges of that function. This, for example, would be a problem if that signal was representing the brightness of an object, since then we would be constantly underestimating how bright our objects really are. \n",
    "\n",
    "Even though measurements of width are not where we are going here, it is worth-while to mention that the measure of width most often used in astronomy is that of **F**ull **W**idth at **H**alf **M**aximum (FWHM). Given that we are dealing with a plateau function picking a \"peak\" of our function is not obvious but let's aim to hit about the mid-point of the plateau."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82ae8ece-2f10-4336-a6a3-bec3203334b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "mid_point_idx = 49\n",
    "\n",
    "plt.plot(f)\n",
    "plt.axvline(mid_point_idx, color=\"black\", label=\"Approx mid-peak\")\n",
    "\n",
    "max_val = f.max()\n",
    "half_max = max_val/2\n",
    "left = np.where(f[:mid_point_idx] > half_max)[0][0]\n",
    "right = np.where(f[mid_point_idx:] < half_max)[0][0] + mid_point_idx\n",
    "\n",
    "print(f\"Idx left: {max_idx}\")\n",
    "print(f\"Idx right: {min_idx}\")\n",
    "\n",
    "plt.scatter(left, half_max)\n",
    "plt.scatter(right, half_max)\n",
    "plt.plot([left, right], [half_max, half_max], label=\"FWHM\")\n",
    "plt.legend()\n",
    "plt.title(\"Plateau function FWHM\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eea37156-b567-4be1-8e6b-723007fc02c0",
   "metadata": {},
   "source": [
    "Notice that the retrieved indices for our left and right points are exactly the same as those for derivatives. This is not always the case, but, in this case, it is not a coincidence either. \n",
    "\n",
    "FWHM has a long statistical backing in the area of signal processing and can usually be related to other properties of distributions. Most famously, for a Gaussian $f(x, x_0, \\sigma)$ the $FWHM=2\\sqrt{2\\ln2}\\sigma \\approx 2.355\\sigma$    \n",
    "\n",
    "Ok, so this was a bit of a side-quest, but how does this help us and how is this useful for us in terms of computer vision problems?        \n",
    "To see that all we have to do is generalize this issue to the 2D dimensions.\n",
    "\n",
    "## Generalizing to images\n",
    "\n",
    "While we are already here - I think it's also worthy to mention that OpenCV is **NOT** the only computer vision library out there (shocking I know). They all pretty much follow the same conventions and the main differences are usually performance and feature completeness, with different libraries usually competing for different niches. Apart from OpenCV, you also have available the `scikit-image` and `scipy-ndimage` libraries, which are more Python oriented and thus tend to perform slower, but are more natural to use. \n",
    "\n",
    "For example, to generate the same \"plateau\" function from above in 2D coordinates could yield something like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c675c3cc-ab59-4bfd-a73f-ad2303152ea9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import ndimage\n",
    "\n",
    "img = np.zeros((256, 256))\n",
    "img[64:-64, 64:-64] = 1\n",
    "img = ndimage.gaussian_filter(img, 8)\n",
    "plt.imshow(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51b62fcd-3d82-4dec-a236-5da7a57e8583",
   "metadata": {},
   "source": [
    "So let's see what the derivative of this image gives us?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b5c5b34-f7f7-44d9-85ac-bab424e803f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "grad_img = np.gradient(img)\n",
    "print(\"N elements: len(grad_img)\")\n",
    "grad_img"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e660943b-5e65-48cb-aa7b-96f260a29d85",
   "metadata": {},
   "source": [
    "Hmm, so we have a list of 2 arrays?!?   \n",
    "That would be a lot more confusing if we didn't know what numerical gradients really are. \n",
    "\n",
    "Without deviating too far into the land of numerical differentiation, the simplest approximation of the first derivative of a function for small enough $h$ is:\n",
    "\n",
    "$$ f'(x) \\approx \\frac{f(x+h) - f(x))}{h}$$\n",
    "\n",
    "But in images, this means we have multiple neighbors to look at, and therefore multiple options to pick from. In an example image cutout:\n",
    "```\n",
    "1 2 3 \n",
    "4 5 6\n",
    "7 8 9\n",
    "```\n",
    "do we look for gradient in point `5` by using elements `4` and `6`, or `2` and `8`, or perhaps even `1` and `9`?\n",
    "\n",
    "Because `np.gradient` doesn't know which one we want it returns both. One for left-to-right gradients and one for up-down gradients. OpenCV, Scipy and others of course, have much more powerful gradient operators that let us pick which one we want including the diagonal ones. We will see some of them in a second, but first let's visualize our gradients."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1046c945-cffc-43dc-9d1d-4d3e697fed13",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 3, figsize=(15, 5), sharey=True)\n",
    "\n",
    "absgrad = np.sqrt(grad_img[0]**2 + grad_img[1]**2)\n",
    "axes[0].imshow(grad_img[0])\n",
    "axes[1].imshow(grad_img[1])\n",
    "axes[2].imshow(absgrad)\n",
    "\n",
    "axes[0].set_title(\"Gradient y\")\n",
    "axes[1].set_title(\"Gradient x\")\n",
    "axes[2].set_title(r\"$\\sqrt{ \\nabla_x^2 + \\nabla_y^2 }$\")\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41c7ef26-f397-45e1-abb6-783d954eea3a",
   "metadata": {},
   "source": [
    "This is basically the basis of **all** edge detectors out there. They are of course smarter than the basic approach demonstrated here, because not only do they include more neighboring pixels in their calculations, but also because they work in cases where there is also noise in the image. Most edge detectors are really noise-prone and struggle to perform well in those circumstances. They also perform some form of edge thinning, because the edge can only be a border 1px wide etc.\n",
    "\n",
    "If you are still struggling to see why this worked, try plotting a row or a column of the image of a square as a function and compare what you get with the plateau function from the start of the document."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "628d652d-9dc5-4ccf-969f-028c4db1afb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# you can do that here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40b45ccb-b2a6-48bf-adbe-3488a827e28c",
   "metadata": {},
   "source": [
    "# Edge detectors\n",
    "\n",
    "If you're really into it you can read all about the additional steps and different derivation operators on any of the following links:     \n",
    "https://scikit-image.org/docs/stable/auto_examples/edges/plot_edge_filter.html          \n",
    "https://docs.opencv.org/4.x/da/d22/tutorial_py_canny.html        \n",
    "https://docs.opencv.org/4.x/d5/d0f/tutorial_py_gradients.html    \n",
    "\n",
    "but in my experience they all kind of work similarly enough to work in our case - because the data we are after lives significantly far above the noise that they do not present a large challenge to any of these algorithms. Therefore we won't do too much comparison testing. \n",
    "\n",
    "What is nice to notice is that it performs two-fold work for us. Firstly, it ensures that the edges follow pixels of the same intensities along the edge. Secondly, it ensures that it thins the edges to 1px width, in such a way that only the, locally, strongest edges remain. Meaning that it doesn't return multiple results for the same edge. \n",
    "\n",
    "Effectively, it provides us with a bitmap that we can use to segment objects in our image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22114e9b-5fc2-4271-a81a-1d3564af7c38",
   "metadata": {},
   "outputs": [],
   "source": [
    "absgrad = cv2.normalize(absgrad, 0, 255)\n",
    "absgrad = cv2.convertScaleAbs(absgrad)\n",
    "threshold, thresholded_image = cv2.threshold(absgrad, 0, 255, cv2.THRESH_BINARY+cv2.THRESH_OTSU)\n",
    "edges = cv2.Canny(thresholded_image, 100, 200)\n",
    "plt.imshow(edges)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2eee223f-f9e7-45ee-a3f3-2d3976eeda72",
   "metadata": {},
   "source": [
    "# Summary\n",
    "\n",
    "* Derivatives can be used to detect peaks of functions\n",
    "  * but they can also be re-purposed to find the \"widths\" of concave and convex functions\n",
    "* FWHM is the most often used definition of signal \"width\" in signal processing\n",
    "  * and of object sizes on the image in Astronomy\n",
    "* All edge detectors are based on detecting changes in pixel brightness values \n",
    "  * they do that by considering pixel brightness values as a function and then they \n",
    "    use the derivatives of that function to find the edges\n",
    "  * there are different ways to define these derivatives, depending on what types of edges you want to look for.\n",
    "  * the job of an edge detector, however, is to find 1 edge for our object, and to find the same edge consistently,\n",
    "    even if that object is very thick. \n",
    "\n",
    "\n",
    "# Extra Section\n",
    "\n",
    "This section can be quite demanding on the memory of your laptop/PC. It isn't crucial to complete as it mostly repeats similar processing as above as it applies to an image of the sky.\n",
    "\n",
    "Let's start with the same copy-paste code we saw in every notebook so far:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93059cd2-87ae-4ac1-8357-fe5b96189749",
   "metadata": {},
   "outputs": [],
   "source": [
    "import astropy.visualization as aviz\n",
    "import astropy.io.fits as fitsio\n",
    "\n",
    "def open_image(imgpath, mode=cv2.IMREAD_GRAYSCALE):\n",
    "    \"\"\"\n",
    "    Open an image as an numpy array.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    imgpath : `str`\n",
    "        Path to the image.\n",
    "    mode : `int`, optional\n",
    "        Mode with which to open the image, i.e. color vs black and white.\n",
    "        Must be one of the OpenCV recognized constants such as \n",
    "        `cv2.IMREAD_GRAYSCALE` or `cv2.IMREAD_COLOR`\n",
    "        \n",
    "    Returns\n",
    "    --------\n",
    "    img : `np.array`\n",
    "        Image.\n",
    "        \n",
    "    Raises\n",
    "    ------\n",
    "    OSError - when the file could not be opened.\n",
    "    \"\"\"\n",
    "    img = cv2.imread(imgpath, mode)\n",
    "    if img is None:\n",
    "        raise OSError(\"Can't open file:\", imgpath)\n",
    "    else:\n",
    "        return img\n",
    "\n",
    "def show(img, ax=None, show=True, title=None, **kwargs):\n",
    "    \"\"\"\n",
    "    Show image using matplotlib.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    img : `np.array`\n",
    "        Image to display.\n",
    "    ax : `matplotlib.pyplot.Axes` or `None`, optional\n",
    "        Ax on which to plot the image. If  no axis is given\n",
    "        a new figure is created.\n",
    "    kwargs : `dict`, optional\n",
    "        Keyword arguments that are passed to `imshow`.\n",
    "    \"\"\"\n",
    "    if ax is None:\n",
    "        fig, ax = plt.subplots()\n",
    "        \n",
    "    ax.imshow(img, **kwargs)\n",
    "    ax.set_title(title, fontsize=22)\n",
    "    return ax"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f78c6732-92cb-4c10-ad05-8bb5566154fe",
   "metadata": {},
   "source": [
    "Then the same magical AstroPy incantation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c66e5c11-4a5d-4c62-b9ee-ea39258e6fe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "hdulist = fitsio.open(\"images/bi327715.fits\")\n",
    "img = hdulist[0].data\n",
    "\n",
    "# let's use the pretty AstoPy stretch to visualize our data.\n",
    "# Naturally we want to avoid doing this and then analyzing this data,\n",
    "# because all of the brightness difference between our trails and background is lost\n",
    "stretch = aviz.HistEqStretch(img)\n",
    "norm = aviz.ImageNormalize(img, stretch=stretch, clip=True)\n",
    "histeq = norm(img).data\n",
    "\n",
    "show(histeq)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03d71f93-2568-4c4e-9be7-65666edfcf6d",
   "metadata": {},
   "source": [
    "And then finally the \"bulk\" of the work. Can you figure out what I did here and, more importantly, why?\n",
    "\n",
    "This one might be a bit harder than the previous questions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5428096d-08bd-46cc-9990-f5b7a4aae648",
   "metadata": {},
   "outputs": [],
   "source": [
    "# to make sure we keep bright trails far away from the background we opt to check this out manually\n",
    "histeq = img.copy()\n",
    "\n",
    "n = 5\n",
    "mean = histeq.mean()\n",
    "std = histeq.std()\n",
    "histeq[histeq > mean+n*std] = 0\n",
    "histeq[histeq < mean-n*std] = 0\n",
    "\n",
    "n = 3\n",
    "mean = histeq.mean()\n",
    "std = histeq.std()\n",
    "histeq[histeq > mean+n*std] = mean+n*std\n",
    "histeq[histeq < mean-n*std] = mean-n*std\n",
    "\n",
    "hist, bars = np.histogram(img, \"auto\", density=True)\n",
    "cdf = np.cumsum(hist*np.diff(bars))\n",
    "                \n",
    "keep_percent = 0.05\n",
    "cutoff = np.where(cdf > 1-keep_percent)[0][0]\n",
    "\n",
    "histeq[histeq < bars[cutoff]] = 0\n",
    "# we could just do this histeq[histeq > 0] = 255\n",
    "#  but too keep some gray and keep it nicer on the eyes \n",
    "# we renormalize differently\n",
    "histeq = (histeq-histeq.mean())/histeq.std()\n",
    "histeq -= histeq.min()\n",
    "\n",
    "show(histeq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ce49021-3a18-43c4-abe5-9b766f230162",
   "metadata": {},
   "outputs": [],
   "source": [
    "histeq = cv2.normalize(histeq, 0, 255)\n",
    "histeq = cv2.convertScaleAbs(histeq)\n",
    "threshold, thresholded_image = cv2.threshold(histeq, 0, 255, cv2.THRESH_BINARY+cv2.THRESH_OTSU)\n",
    "edges = cv2.Canny(thresholded_image, 100, 200)\n",
    "show(edges)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
